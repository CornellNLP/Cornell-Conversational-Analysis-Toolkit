{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing Surprise With ConvoKit\n",
    "=====================\n",
    "This notebook provides a demo of how to use the Surprise transformer to compute surprise across a corpus. In this demo, we will use the Surprise transformer to compute Speaker Convo Diversity, a measure of how surprising a speaker's participation in one conversation is compared to their participation in all other conversations. We will then compare the results to those obtained using the actual SpeakerConvoDiversity transformer. We eventually want to use the Surprise transformer within the SpeakerConvoDiversity transformer to reduce redundancy, but for now, this demo serves as a sanity check on the correctness of the Surprise transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import convokit\n",
    "import itertools\n",
    "import numpy as np\n",
    "import spacy\n",
    "from convokit import Corpus, download, Surprise\n",
    "from convokit.text_processing import TextProcessor, TextParser\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Load a corpus\n",
    "--------\n",
    "For now, we will use data from the subreddit r/Cornell to demonstrate the functionality of this transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at /home/axl4/.convokit/downloads/subreddit-Cornell\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus(filename=download('subreddit-Cornell'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 7568\n",
      "Number of Utterances: 74467\n",
      "Number of Conversations: 10744\n"
     ]
    }
   ],
   "source": [
    "corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to speed up the demo, we will take just the top 100 most active speakers (based on the number of conversations they participate in)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPEAKER_BLACKLIST = ['[deleted]', 'DeltaBot', 'AutoModerator']\n",
    "def utterance_is_valid(utterance):\n",
    "    return utterance.speaker.id not in SPEAKER_BLACKLIST and utterance.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/axl4/Cornell-Conversational-Analysis-Toolkit/convokit/model/corpus.py:1213: FutureWarning: set_info() is deprecated and will be removed in a future release. Use add_meta() instead.\n",
      "/home/axl4/Cornell-Conversational-Analysis-Toolkit/convokit/model/corpus.py:1219: FutureWarning: set_info() is deprecated and will be removed in a future release. Use add_meta() instead.\n"
     ]
    }
   ],
   "source": [
    "corpus.organize_speaker_convo_history(utterance_filter=utterance_is_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_activities = corpus.get_attribute_table('speaker', ['n_convos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_convos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>laveritecestla</th>\n",
       "      <td>781.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EQUASHNZRKUL</th>\n",
       "      <td>726.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CornHellUniversity</th>\n",
       "      <td>696.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3hasiangod</th>\n",
       "      <td>647.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ilovemymemesboo</th>\n",
       "      <td>430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>omgdonerkebab</th>\n",
       "      <td>425.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cartesiancategory</th>\n",
       "      <td>341.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cornell256</th>\n",
       "      <td>330.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mushiettake</th>\n",
       "      <td>321.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fencerman2</th>\n",
       "      <td>298.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    n_convos\n",
       "id                          \n",
       "laveritecestla         781.0\n",
       "EQUASHNZRKUL           726.0\n",
       "CornHellUniversity     696.0\n",
       "t3hasiangod            647.0\n",
       "ilovemymemesboo        430.0\n",
       "omgdonerkebab          425.0\n",
       "cartesiancategory      341.0\n",
       "cornell256             330.0\n",
       "mushiettake            321.0\n",
       "Fencerman2             298.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speaker_activities.sort_values('n_convos', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_speakers = speaker_activities.sort_values('n_convos', ascending=False).head(100).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "subset_utts = [list(corpus.get_speaker(speaker).iter_utterances(selector=utterance_is_valid)) for speaker in top_speakers]\n",
    "subset_corpus = Corpus(utterances=list(itertools.chain(*subset_utts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 100\n",
      "Number of Utterances: 20550\n",
      "Number of Conversations: 6866\n"
     ]
    }
   ],
   "source": [
    "subset_corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Create instance of Surprise transformer\n",
    "---------------\n",
    "`target_sample_size` and `context_sample_size` specify the minimum number of tokens that should be in the target and context respectively. If the target or context is too short, the transformer will set the surprise to be `nan`. If we sent these to simply be 1, the most surprising statements tend to just be the very short statements. The transformer takes `n_samples` samples from the target and context transformer (where samples are of size corresponding to `target_sample_size` and `context_sample_size`). It calculates cross entropy for each pair of samples and takes the average to get the final surprise score. This is done to minimize effect of length on scores.\n",
    "\n",
    "`model_key_selector` defines how utterances in a corpus should be mapped to a model. It takes in an utterance and returns the key for the corresponding model. For this demo we want to map utterances to models based on their speaker and conversation ids.\n",
    "\n",
    "The transformer also has an optional `cv` to customize the `scikit-learn` `CountVectorizer` used by the transformer to vectorize text. Since we are comparing Surprise to the SpeakerConvoDiversity transformer, we want to make sure that our transformer handles tokenization the same way as SpeakerConvoDiversity, so we will pass in a custom tokenizer function.\n",
    "\n",
    "The `smooth` parameter determines whether the transformer uses +1 laplace smoothing (`smooth = True`) or naively replaces 0 counts with 1's (`smooth = False`) as SpeakerConvoDiversity does. Here we'll set `smooth = False` since we're comparing the results of Surprise with SpeakerConvoDiversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "spacy_nlp = spacy.load('en_core_web_sm', disable=['ner','parser', 'tagger', 'lemmatizer'])\n",
    "for utt in subset_corpus.iter_utterances():\n",
    "    utt.meta['joined_tokens'] = [t.text.lower() for t in spacy_nlp(utt.text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "surp = Surprise(tokenizer=lambda x: x, model_key_selector=lambda utt: '_'.join([utt.speaker.id, utt.conversation_id]), target_sample_size=100, context_sample_size=1000, n_samples=50, smooth=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fit1: 20550it [00:16, 1267.10it/s]\n",
      "fit2: 100%|██████████| 15394/15394 [00:00<00:00, 989140.20it/s]\n"
     ]
    }
   ],
   "source": [
    "surp = surp.fit(subset_corpus, text_func=lambda utt: [list(itertools.chain(*[u.meta['joined_tokens'] for u in utt.speaker.iter_utterances() if u.conversation_id != utt.conversation_id]))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Transform corpus\n",
    "--------\n",
    "We'll call `transform` with object type `'speaker'` so that surprise scores will be added as a metadata field for each speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "transform: 100it [13:21,  8.01s/it]\n"
     ]
    }
   ],
   "source": [
    "transformed_corpus = surp.transform(subset_corpus, 'speaker')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis\n",
    "------\n",
    "Let's take a look at some of the most surprising speaker conversation involvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "def combine_dicts(x,y):\n",
    "    x.update(y)\n",
    "    return x\n",
    "surprise_scores = reduce(combine_dicts, transformed_corpus.get_speakers_dataframe()['meta.surprise'].values)\n",
    "suprise_series = pd.Series(surprise_scores).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GROUP_EQUASHNZRKUL_815y6t__MODEL_EQUASHNZRKUL_815y6t            6.903181\n",
       "GROUP_SwissWatchesOnly_8g5q88__MODEL_SwissWatchesOnly_8g5q88    6.884900\n",
       "GROUP_SwissWatchesOnly_67cljd__MODEL_SwissWatchesOnly_67cljd    6.819719\n",
       "GROUP_CornellMan333_9iwucv__MODEL_CornellMan333_9iwucv          6.801696\n",
       "GROUP_EQUASHNZRKUL_73xuw6__MODEL_EQUASHNZRKUL_73xuw6            6.797471\n",
       "GROUP_Udontlikecake_7rj6a0__MODEL_Udontlikecake_7rj6a0          6.796684\n",
       "GROUP_Straight_Derpin_5kst5l__MODEL_Straight_Derpin_5kst5l      6.768749\n",
       "GROUP_laveritecestla_6v4ysm__MODEL_laveritecestla_6v4ysm        6.745163\n",
       "GROUP_SharkHogBestHog_9f8mou__MODEL_SharkHogBestHog_9f8mou      6.738350\n",
       "GROUP_ClawofBeta_52u1nu__MODEL_ClawofBeta_52u1nu                6.736324\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_surprising = suprise_series.sort_values(ascending=False).head(10)\n",
    "most_surprising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at some of the least surprising entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GROUP_Unga_Bunga_30ac0l__MODEL_Unga_Bunga_30ac0l              5.544727\n",
       "GROUP_crash_over-ride_8f7b0y__MODEL_crash_over-ride_8f7b0y    5.607746\n",
       "GROUP_Bisphosphate_7r8nu1__MODEL_Bisphosphate_7r8nu1          5.613737\n",
       "GROUP_crash_over-ride_6bjxnm__MODEL_crash_over-ride_6bjxnm    5.621535\n",
       "GROUP_crash_over-ride_30zba1__MODEL_crash_over-ride_30zba1    5.622496\n",
       "GROUP_omgdonerkebab_v4a3p__MODEL_omgdonerkebab_v4a3p          5.660275\n",
       "GROUP_crash_over-ride_2vhtzx__MODEL_crash_over-ride_2vhtzx    5.666062\n",
       "GROUP_crash_over-ride_2vtgvc__MODEL_crash_over-ride_2vtgvc    5.673908\n",
       "GROUP_crash_over-ride_t6w01__MODEL_crash_over-ride_t6w01      5.674109\n",
       "GROUP_crash_over-ride_9b132c__MODEL_crash_over-ride_9b132c    5.683613\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "least_surprising = suprise_series.sort_values(ascending=True).head(10)\n",
    "least_surprising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to SpeakerConvoDiversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/20550 utterances processed\n",
      "2000/20550 utterances processed\n",
      "3000/20550 utterances processed\n",
      "4000/20550 utterances processed\n",
      "5000/20550 utterances processed\n",
      "6000/20550 utterances processed\n",
      "7000/20550 utterances processed\n",
      "8000/20550 utterances processed\n",
      "9000/20550 utterances processed\n",
      "10000/20550 utterances processed\n",
      "11000/20550 utterances processed\n",
      "12000/20550 utterances processed\n",
      "13000/20550 utterances processed\n",
      "14000/20550 utterances processed\n",
      "15000/20550 utterances processed\n",
      "16000/20550 utterances processed\n",
      "17000/20550 utterances processed\n",
      "18000/20550 utterances processed\n",
      "19000/20550 utterances processed\n",
      "20000/20550 utterances processed\n",
      "20550/20550 utterances processed\n"
     ]
    }
   ],
   "source": [
    "from convokit.text_processing import TextProcessor, TextParser\n",
    "\n",
    "tokenizer = TextParser(mode='tokenize', output_field='tokens', verbosity=1000)\n",
    "subset_corpus = tokenizer.transform(subset_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import SpeakerConvoDiversity\n",
    "\n",
    "scd = SpeakerConvoDiversity('div', select_fn=lambda df, row, aux: (df.convo_id != row.convo_id) & (df.speaker == row.speaker), speaker_cols=['n_convos'], aux_input={'n_iters': 50, 'cmp_sample_size': 100, 'ref_sample_size': 1000}, verbosity=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joining tokens across conversation utterances\n",
      "1000 / 15394\n",
      "2000 / 15394\n",
      "3000 / 15394\n",
      "4000 / 15394\n",
      "5000 / 15394\n",
      "6000 / 15394\n",
      "7000 / 15394\n",
      "8000 / 15394\n",
      "9000 / 15394\n",
      "10000 / 15394\n",
      "11000 / 15394\n",
      "12000 / 15394\n",
      "13000 / 15394\n",
      "14000 / 15394\n",
      "15000 / 15394\n"
     ]
    }
   ],
   "source": [
    "div_transformed = scd.transform(subset_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the speaker convo entries that have the highest diversity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>convo_id</th>\n",
       "      <th>convo_idx</th>\n",
       "      <th>div</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Straight_Derpin__5kst5l</th>\n",
       "      <td>Straight_Derpin</td>\n",
       "      <td>5kst5l</td>\n",
       "      <td>34</td>\n",
       "      <td>6.822236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr_Narwhal__6h08sg</th>\n",
       "      <td>Dr_Narwhal</td>\n",
       "      <td>6h08sg</td>\n",
       "      <td>75</td>\n",
       "      <td>6.523284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sasha07974__8v40c1</th>\n",
       "      <td>sasha07974</td>\n",
       "      <td>8v40c1</td>\n",
       "      <td>42</td>\n",
       "      <td>6.267265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mushiettake__89mbvs</th>\n",
       "      <td>mushiettake</td>\n",
       "      <td>89mbvs</td>\n",
       "      <td>269</td>\n",
       "      <td>6.136225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SwissWatchesOnly__9hcpip</th>\n",
       "      <td>SwissWatchesOnly</td>\n",
       "      <td>9hcpip</td>\n",
       "      <td>129</td>\n",
       "      <td>6.134547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blackashi__2xxkm4</th>\n",
       "      <td>blackashi</td>\n",
       "      <td>2xxkm4</td>\n",
       "      <td>6</td>\n",
       "      <td>6.114604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScottVandeberg__8tlcdl</th>\n",
       "      <td>ScottVandeberg</td>\n",
       "      <td>8tlcdl</td>\n",
       "      <td>81</td>\n",
       "      <td>6.081968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cartesiancategory__8bdf5g</th>\n",
       "      <td>cartesiancategory</td>\n",
       "      <td>8bdf5g</td>\n",
       "      <td>310</td>\n",
       "      <td>6.075852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agottler__9iyo8u</th>\n",
       "      <td>agottler</td>\n",
       "      <td>9iyo8u</td>\n",
       "      <td>66</td>\n",
       "      <td>6.073317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3hasiangod__5v6sqb</th>\n",
       "      <td>t3hasiangod</td>\n",
       "      <td>5v6sqb</td>\n",
       "      <td>590</td>\n",
       "      <td>6.059111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     speaker convo_id  convo_idx       div\n",
       "id                                                                        \n",
       "Straight_Derpin__5kst5l      Straight_Derpin   5kst5l         34  6.822236\n",
       "Dr_Narwhal__6h08sg                Dr_Narwhal   6h08sg         75  6.523284\n",
       "sasha07974__8v40c1                sasha07974   8v40c1         42  6.267265\n",
       "mushiettake__89mbvs              mushiettake   89mbvs        269  6.136225\n",
       "SwissWatchesOnly__9hcpip    SwissWatchesOnly   9hcpip        129  6.134547\n",
       "blackashi__2xxkm4                  blackashi   2xxkm4          6  6.114604\n",
       "ScottVandeberg__8tlcdl        ScottVandeberg   8tlcdl         81  6.081968\n",
       "cartesiancategory__8bdf5g  cartesiancategory   8bdf5g        310  6.075852\n",
       "agottler__9iyo8u                    agottler   9iyo8u         66  6.073317\n",
       "t3hasiangod__5v6sqb              t3hasiangod   5v6sqb        590  6.059111"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div_transformed.get_speaker_convo_attribute_table(attrs=['div']).sort_values('div', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the diversity scores returned by `SpeakerConvoDiversity` are slightly different from the scores returned by the `Surprise` transformer. This difference can be attributed to the addition of Laplace smoothing in the `Surprise` transformer to account for out of vocabulary tokens. The `SpeakerConvoDiversity` transformer deals with OOV tokens by simply treating their count as 1. If you run the `Surprise` transformer with the `smooth` flag set to false, the transformer will treat OOV tokens the same way `SpeakerConvoDiversity` does. When run without smoothing, the `Surprise` transformer returns the same scores as `SpeakerConvoDiversity`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the least diverse speaker-convo entries based on the SpeakerConvoDiversity transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>convo_id</th>\n",
       "      <th>convo_idx</th>\n",
       "      <th>div</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CornellMan333__9epekx</th>\n",
       "      <td>CornellMan333</td>\n",
       "      <td>9epekx</td>\n",
       "      <td>56</td>\n",
       "      <td>5.041151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laveritecestla__4pylgl</th>\n",
       "      <td>laveritecestla</td>\n",
       "      <td>4pylgl</td>\n",
       "      <td>74</td>\n",
       "      <td>5.161081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CornellMan333__9j2exy</th>\n",
       "      <td>CornellMan333</td>\n",
       "      <td>9j2exy</td>\n",
       "      <td>67</td>\n",
       "      <td>5.189820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cryptkeep__3zgnom</th>\n",
       "      <td>cryptkeep</td>\n",
       "      <td>3zgnom</td>\n",
       "      <td>40</td>\n",
       "      <td>5.207361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voluminous_lexicon__6v3oa0</th>\n",
       "      <td>voluminous_lexicon</td>\n",
       "      <td>6v3oa0</td>\n",
       "      <td>9</td>\n",
       "      <td>5.225655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fencerman2__66rq5i</th>\n",
       "      <td>Fencerman2</td>\n",
       "      <td>66rq5i</td>\n",
       "      <td>51</td>\n",
       "      <td>5.230217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iBeReese__1uuldh</th>\n",
       "      <td>iBeReese</td>\n",
       "      <td>1uuldh</td>\n",
       "      <td>6</td>\n",
       "      <td>5.236974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BuildAnything__6v0x2j</th>\n",
       "      <td>BuildAnything</td>\n",
       "      <td>6v0x2j</td>\n",
       "      <td>17</td>\n",
       "      <td>5.244524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpookBusters__93abug</th>\n",
       "      <td>SpookBusters</td>\n",
       "      <td>93abug</td>\n",
       "      <td>225</td>\n",
       "      <td>5.248574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SantaSoul__6zqlyk</th>\n",
       "      <td>SantaSoul</td>\n",
       "      <td>6zqlyk</td>\n",
       "      <td>35</td>\n",
       "      <td>5.257848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       speaker convo_id  convo_idx       div\n",
       "id                                                                          \n",
       "CornellMan333__9epekx            CornellMan333   9epekx         56  5.041151\n",
       "laveritecestla__4pylgl          laveritecestla   4pylgl         74  5.161081\n",
       "CornellMan333__9j2exy            CornellMan333   9j2exy         67  5.189820\n",
       "cryptkeep__3zgnom                    cryptkeep   3zgnom         40  5.207361\n",
       "voluminous_lexicon__6v3oa0  voluminous_lexicon   6v3oa0          9  5.225655\n",
       "Fencerman2__66rq5i                  Fencerman2   66rq5i         51  5.230217\n",
       "iBeReese__1uuldh                      iBeReese   1uuldh          6  5.236974\n",
       "BuildAnything__6v0x2j            BuildAnything   6v0x2j         17  5.244524\n",
       "SpookBusters__93abug              SpookBusters   93abug        225  5.248574\n",
       "SantaSoul__6zqlyk                    SantaSoul   6zqlyk         35  5.257848"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div_transformed.get_speaker_convo_attribute_table(attrs=['div']).sort_values('div').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surprise With Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "spacy_nlp = spacy.load('en_core_web_sm', disable=['ner','parser', 'tagger', 'lemmatizer'])\n",
    "for utt in subset_corpus.iter_utterances():\n",
    "    utt.meta['joined_tokens'] = [t.text.lower() for t in spacy_nlp(utt.text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fit1: 20550it [00:11, 1826.44it/s]\n",
      "fit2: 100%|██████████| 15394/15394 [00:00<00:00, 993416.66it/s]\n",
      "transform: 100it [12:08,  7.29s/it]\n"
     ]
    }
   ],
   "source": [
    "surp = Surprise(tokenizer=lambda x: x, model_key_selector=lambda utt: '_'.join([utt.speaker.id, utt.conversation_id]), target_sample_size=100, context_sample_size=1000, n_samples=50, smooth=True, surprise_attr_name='surprise_smoothed')\n",
    "surp.fit(subset_corpus, text_func=lambda utt: [list(itertools.chain(*[u.meta['joined_tokens'] for u in utt.speaker.iter_utterances() if u.conversation_id != utt.conversation_id]))])\n",
    "transformed_corpus = surp.transform(subset_corpus, 'speaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "def combine_dicts(x,y):\n",
    "    x.update(y)\n",
    "    return x\n",
    "surprise_scores = reduce(combine_dicts, transformed_corpus.get_speakers_dataframe()['meta.surprise_smoothed'].values)\n",
    "suprise_series = pd.Series(surprise_scores).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GROUP_EQUASHNZRKUL_815y6t__MODEL_EQUASHNZRKUL_815y6t            7.218165\n",
       "GROUP_SwissWatchesOnly_8g5q88__MODEL_SwissWatchesOnly_8g5q88    7.205426\n",
       "GROUP_SwissWatchesOnly_67cljd__MODEL_SwissWatchesOnly_67cljd    7.137258\n",
       "GROUP_EQUASHNZRKUL_73xuw6__MODEL_EQUASHNZRKUL_73xuw6            7.089950\n",
       "GROUP_CornellMan333_9iwucv__MODEL_CornellMan333_9iwucv          7.070621\n",
       "GROUP_Straight_Derpin_5kst5l__MODEL_Straight_Derpin_5kst5l      7.062313\n",
       "GROUP_ClawofBeta_52u1nu__MODEL_ClawofBeta_52u1nu                7.049150\n",
       "GROUP_syntheticity_97zg9z__MODEL_syntheticity_97zg9z            7.044579\n",
       "GROUP_Udontlikecake_7rj6a0__MODEL_Udontlikecake_7rj6a0          7.043805\n",
       "GROUP_Enyo287_3s4yj4__MODEL_Enyo287_3s4yj4                      7.039872\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_surprising = suprise_series.sort_values(ascending=False).head(10)\n",
    "most_surprising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GROUP_Unga_Bunga_30ac0l__MODEL_Unga_Bunga_30ac0l              5.869289\n",
       "GROUP_crash_over-ride_6bjxnm__MODEL_crash_over-ride_6bjxnm    5.938821\n",
       "GROUP_Bisphosphate_7r8nu1__MODEL_Bisphosphate_7r8nu1          5.941510\n",
       "GROUP_omgdonerkebab_v4a3p__MODEL_omgdonerkebab_v4a3p          5.942420\n",
       "GROUP_crash_over-ride_t6w01__MODEL_crash_over-ride_t6w01      5.960937\n",
       "GROUP_crash_over-ride_9b132c__MODEL_crash_over-ride_9b132c    5.975243\n",
       "GROUP_crash_over-ride_7owfvv__MODEL_crash_over-ride_7owfvv    5.979871\n",
       "GROUP_crash_over-ride_2vhtzx__MODEL_crash_over-ride_2vhtzx    5.981664\n",
       "GROUP_crash_over-ride_8f7b0y__MODEL_crash_over-ride_8f7b0y    5.989878\n",
       "GROUP_crash_over-ride_llc0q__MODEL_crash_over-ride_llc0q      5.993079\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "least_surprising = suprise_series.sort_values(ascending=True).head(10)\n",
    "least_surprising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SpeakerConvoDiversity reimplemented using Surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import SpeakerConvoDiversityWrapper\n",
    "from convokit.speakerConvoDiversity.speakerConvoDiversity2 import SpeakerConvoDiversityWrapper as SpeakerConvoDiversityWrapper2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at /home/axl4/.convokit/downloads/subreddit-Cornell\n",
      "Number of Speakers: 7568\n",
      "Number of Utterances: 74467\n",
      "Number of Conversations: 10744\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus(filename=download('subreddit-Cornell'))\n",
    "corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/axl4/Cornell-Conversational-Analysis-Toolkit/convokit/model/corpus.py:1213: FutureWarning: set_info() is deprecated and will be removed in a future release. Use add_meta() instead.\n",
      "/home/axl4/Cornell-Conversational-Analysis-Toolkit/convokit/model/corpus.py:1219: FutureWarning: set_info() is deprecated and will be removed in a future release. Use add_meta() instead.\n"
     ]
    }
   ],
   "source": [
    "SPEAKER_BLACKLIST = ['[deleted]', 'DeltaBot','AutoModerator']\n",
    "def utterance_is_valid(utterance):\n",
    "    return (utterance.id != utterance.conversation_id) and (utterance.speaker.id not in SPEAKER_BLACKLIST)\n",
    "\n",
    "corpus.organize_speaker_convo_history(utterance_filter=utterance_is_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_activities = corpus.get_attribute_table('speaker',['n_convos'])\n",
    "top_speakers = speaker_activities.sort_values('n_convos', ascending=False).head(25).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 25\n",
      "Number of Utterances: 10909\n",
      "Number of Conversations: 5042\n"
     ]
    }
   ],
   "source": [
    "subset_utts = []\n",
    "for speaker in top_speakers:\n",
    "    subset_utts += list(corpus.get_speaker(speaker).iter_utterances(selector=utterance_is_valid))\n",
    "subset_corpus = Corpus(utterances=subset_utts)\n",
    "subset_corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/10909 utterances processed\n",
      "2000/10909 utterances processed\n",
      "3000/10909 utterances processed\n",
      "4000/10909 utterances processed\n",
      "5000/10909 utterances processed\n",
      "6000/10909 utterances processed\n",
      "7000/10909 utterances processed\n",
      "8000/10909 utterances processed\n",
      "9000/10909 utterances processed\n",
      "10000/10909 utterances processed\n",
      "10909/10909 utterances processed\n"
     ]
    }
   ],
   "source": [
    "tokenizer = TextParser(mode='tokenize', output_field='tokens', verbosity=1000)\n",
    "subset_corpus = tokenizer.transform(subset_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "scd = SpeakerConvoDiversityWrapper(lifestage_size=2, max_exp=20,\n",
    "                sample_size=20, min_n_utterances=1, n_iters=50, cohort_delta=60*60*24*30*2, verbosity=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting lifestages\n",
      "getting within diversity\n",
      "joining tokens across conversation utterances\n",
      "100 / 396\n",
      "200 / 396\n",
      "300 / 396\n",
      "getting across diversity\n",
      "joining tokens across conversation utterances\n",
      "100 / 396\n",
      "200 / 396\n",
      "300 / 396\n",
      "getting relative diversity\n",
      "100 / 380\n",
      "200 / 380\n",
      "300 / 380\n"
     ]
    }
   ],
   "source": [
    "subset_corpus = scd.transform(subset_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>convo_id</th>\n",
       "      <th>convo_idx</th>\n",
       "      <th>div__self</th>\n",
       "      <th>div__other</th>\n",
       "      <th>div__adj</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>laveritecestla__1t542i</th>\n",
       "      <td>laveritecestla</td>\n",
       "      <td>1t542i</td>\n",
       "      <td>0</td>\n",
       "      <td>2.882890</td>\n",
       "      <td>2.945694</td>\n",
       "      <td>0.062805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laveritecestla__22i7ke</th>\n",
       "      <td>laveritecestla</td>\n",
       "      <td>22i7ke</td>\n",
       "      <td>1</td>\n",
       "      <td>2.863870</td>\n",
       "      <td>2.965638</td>\n",
       "      <td>0.101768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laveritecestla__2kk0n2</th>\n",
       "      <td>laveritecestla</td>\n",
       "      <td>2kk0n2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.971524</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laveritecestla__31hwi8</th>\n",
       "      <td>laveritecestla</td>\n",
       "      <td>31hwi8</td>\n",
       "      <td>8</td>\n",
       "      <td>2.927225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laveritecestla__34ycz6</th>\n",
       "      <td>laveritecestla</td>\n",
       "      <td>34ycz6</td>\n",
       "      <td>9</td>\n",
       "      <td>2.958407</td>\n",
       "      <td>2.969732</td>\n",
       "      <td>0.011326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laveritecestla__36bxln</th>\n",
       "      <td>laveritecestla</td>\n",
       "      <td>36bxln</td>\n",
       "      <td>10</td>\n",
       "      <td>2.949173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laveritecestla__36tnnq</th>\n",
       "      <td>laveritecestla</td>\n",
       "      <td>36tnnq</td>\n",
       "      <td>11</td>\n",
       "      <td>2.925592</td>\n",
       "      <td>2.965691</td>\n",
       "      <td>0.040099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laveritecestla__3856f2</th>\n",
       "      <td>laveritecestla</td>\n",
       "      <td>3856f2</td>\n",
       "      <td>12</td>\n",
       "      <td>2.969732</td>\n",
       "      <td>2.942005</td>\n",
       "      <td>-0.027727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laveritecestla__37vkfp</th>\n",
       "      <td>laveritecestla</td>\n",
       "      <td>37vkfp</td>\n",
       "      <td>13</td>\n",
       "      <td>2.957332</td>\n",
       "      <td>2.951916</td>\n",
       "      <td>-0.005416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laveritecestla__39m37w</th>\n",
       "      <td>laveritecestla</td>\n",
       "      <td>39m37w</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.951187</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               speaker convo_id  convo_idx  div__self  \\\n",
       "id                                                                      \n",
       "laveritecestla__1t542i  laveritecestla   1t542i          0   2.882890   \n",
       "laveritecestla__22i7ke  laveritecestla   22i7ke          1   2.863870   \n",
       "laveritecestla__2kk0n2  laveritecestla   2kk0n2          3        NaN   \n",
       "laveritecestla__31hwi8  laveritecestla   31hwi8          8   2.927225   \n",
       "laveritecestla__34ycz6  laveritecestla   34ycz6          9   2.958407   \n",
       "laveritecestla__36bxln  laveritecestla   36bxln         10   2.949173   \n",
       "laveritecestla__36tnnq  laveritecestla   36tnnq         11   2.925592   \n",
       "laveritecestla__3856f2  laveritecestla   3856f2         12   2.969732   \n",
       "laveritecestla__37vkfp  laveritecestla   37vkfp         13   2.957332   \n",
       "laveritecestla__39m37w  laveritecestla   39m37w         15        NaN   \n",
       "\n",
       "                        div__other  div__adj  \n",
       "id                                            \n",
       "laveritecestla__1t542i    2.945694  0.062805  \n",
       "laveritecestla__22i7ke    2.965638  0.101768  \n",
       "laveritecestla__2kk0n2    2.971524       NaN  \n",
       "laveritecestla__31hwi8         NaN       NaN  \n",
       "laveritecestla__34ycz6    2.969732  0.011326  \n",
       "laveritecestla__36bxln         NaN       NaN  \n",
       "laveritecestla__36tnnq    2.965691  0.040099  \n",
       "laveritecestla__3856f2    2.942005 -0.027727  \n",
       "laveritecestla__37vkfp    2.951916 -0.005416  \n",
       "laveritecestla__39m37w    2.951187       NaN  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_corpus.get_speaker_convo_attribute_table(attrs=['div__self', 'div__other', 'div__adj']).dropna(subset=['div__self', 'div__other', 'div__adj'], how='all').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 25\n",
      "Number of Utterances: 10909\n",
      "Number of Conversations: 5042\n"
     ]
    }
   ],
   "source": [
    "subset_corpus = Corpus(utterances=subset_utts)\n",
    "subset_corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "scd = SpeakerConvoDiversityWrapper2(lifestage_size=2, max_exp=20,\n",
    "                sample_size=20, min_n_utterances=1, n_iters=50, cohort_delta=60*60*24*30*2, verbosity=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fit1: 41it [00:00, 403.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting lifestages\n",
      "getting within diversity\n",
      "joining tokens across conversation utterances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fit1: 10909it [00:24, 450.05it/s]\n",
      "fit2: 100%|██████████| 8143/8143 [00:00<00:00, 938637.91it/s]\n",
      "transform: 25it [00:24,  1.02it/s]\n",
      "set output: 25it [04:47, 11.50s/it]\n",
      "fit1: 20it [00:00, 195.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting across diversity\n",
      "joining tokens across conversation utterances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fit1: 10909it [00:46, 236.85it/s]\n",
      "fit2: 100%|██████████| 8143/8143 [00:00<00:00, 359559.71it/s]\n",
      "transform: 1it [00:00,  1.57it/s]/home/axl4/Cornell-Conversational-Analysis-Toolkit/convokit/surprise/surprise.py:41: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "transform: 25it [00:17,  1.44it/s]\n",
      "set output: 25it [03:30,  8.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting relative diversity\n",
      "100 / 5104\n",
      "200 / 5104\n",
      "300 / 5104\n",
      "400 / 5104\n",
      "500 / 5104\n",
      "600 / 5104\n",
      "700 / 5104\n",
      "800 / 5104\n",
      "900 / 5104\n",
      "1000 / 5104\n",
      "1100 / 5104\n",
      "1200 / 5104\n",
      "1300 / 5104\n",
      "1400 / 5104\n",
      "1500 / 5104\n",
      "1600 / 5104\n",
      "1700 / 5104\n",
      "1800 / 5104\n",
      "1900 / 5104\n",
      "2000 / 5104\n",
      "2100 / 5104\n",
      "2200 / 5104\n",
      "2300 / 5104\n",
      "2400 / 5104\n",
      "2500 / 5104\n",
      "2600 / 5104\n",
      "2700 / 5104\n",
      "2800 / 5104\n",
      "2900 / 5104\n",
      "3000 / 5104\n",
      "3100 / 5104\n",
      "3200 / 5104\n",
      "3300 / 5104\n",
      "3400 / 5104\n",
      "3500 / 5104\n",
      "3600 / 5104\n",
      "3700 / 5104\n",
      "3800 / 5104\n",
      "3900 / 5104\n",
      "4000 / 5104\n",
      "4100 / 5104\n",
      "4200 / 5104\n",
      "4300 / 5104\n",
      "4400 / 5104\n",
      "4500 / 5104\n",
      "4600 / 5104\n",
      "4700 / 5104\n",
      "4800 / 5104\n",
      "4900 / 5104\n",
      "5000 / 5104\n",
      "5100 / 5104\n"
     ]
    }
   ],
   "source": [
    "subset_corpus = scd.transform(subset_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>convo_id</th>\n",
       "      <th>convo_idx</th>\n",
       "      <th>div__self</th>\n",
       "      <th>div__other</th>\n",
       "      <th>div__adj</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>laveritecestla__1t542i</th>\n",
       "      <td>laveritecestla</td>\n",
       "      <td>1t542i</td>\n",
       "      <td>0</td>\n",
       "      <td>2.929177</td>\n",
       "      <td>2.932982</td>\n",
       "      <td>0.003806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laveritecestla__22i7ke</th>\n",
       "      <td>laveritecestla</td>\n",
       "      <td>22i7ke</td>\n",
       "      <td>1</td>\n",
       "      <td>2.912328</td>\n",
       "      <td>2.959453</td>\n",
       "      <td>0.047125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laveritecestla__2kk0n2</th>\n",
       "      <td>laveritecestla</td>\n",
       "      <td>2kk0n2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.974585</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laveritecestla__31hwi8</th>\n",
       "      <td>laveritecestla</td>\n",
       "      <td>31hwi8</td>\n",
       "      <td>8</td>\n",
       "      <td>2.952755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laveritecestla__34ycz6</th>\n",
       "      <td>laveritecestla</td>\n",
       "      <td>34ycz6</td>\n",
       "      <td>9</td>\n",
       "      <td>2.939873</td>\n",
       "      <td>2.969563</td>\n",
       "      <td>0.029690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laveritecestla__36bxln</th>\n",
       "      <td>laveritecestla</td>\n",
       "      <td>36bxln</td>\n",
       "      <td>10</td>\n",
       "      <td>2.937259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laveritecestla__36tnnq</th>\n",
       "      <td>laveritecestla</td>\n",
       "      <td>36tnnq</td>\n",
       "      <td>11</td>\n",
       "      <td>2.930667</td>\n",
       "      <td>2.962513</td>\n",
       "      <td>0.031846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laveritecestla__3856f2</th>\n",
       "      <td>laveritecestla</td>\n",
       "      <td>3856f2</td>\n",
       "      <td>12</td>\n",
       "      <td>2.968516</td>\n",
       "      <td>2.946440</td>\n",
       "      <td>-0.022076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laveritecestla__37vkfp</th>\n",
       "      <td>laveritecestla</td>\n",
       "      <td>37vkfp</td>\n",
       "      <td>13</td>\n",
       "      <td>2.952691</td>\n",
       "      <td>2.958236</td>\n",
       "      <td>0.005544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laveritecestla__39m37w</th>\n",
       "      <td>laveritecestla</td>\n",
       "      <td>39m37w</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.957072</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               speaker convo_id  convo_idx  div__self  \\\n",
       "id                                                                      \n",
       "laveritecestla__1t542i  laveritecestla   1t542i          0   2.929177   \n",
       "laveritecestla__22i7ke  laveritecestla   22i7ke          1   2.912328   \n",
       "laveritecestla__2kk0n2  laveritecestla   2kk0n2          3        NaN   \n",
       "laveritecestla__31hwi8  laveritecestla   31hwi8          8   2.952755   \n",
       "laveritecestla__34ycz6  laveritecestla   34ycz6          9   2.939873   \n",
       "laveritecestla__36bxln  laveritecestla   36bxln         10   2.937259   \n",
       "laveritecestla__36tnnq  laveritecestla   36tnnq         11   2.930667   \n",
       "laveritecestla__3856f2  laveritecestla   3856f2         12   2.968516   \n",
       "laveritecestla__37vkfp  laveritecestla   37vkfp         13   2.952691   \n",
       "laveritecestla__39m37w  laveritecestla   39m37w         15        NaN   \n",
       "\n",
       "                        div__other  div__adj  \n",
       "id                                            \n",
       "laveritecestla__1t542i    2.932982  0.003806  \n",
       "laveritecestla__22i7ke    2.959453  0.047125  \n",
       "laveritecestla__2kk0n2    2.974585       NaN  \n",
       "laveritecestla__31hwi8         NaN       NaN  \n",
       "laveritecestla__34ycz6    2.969563  0.029690  \n",
       "laveritecestla__36bxln         NaN       NaN  \n",
       "laveritecestla__36tnnq    2.962513  0.031846  \n",
       "laveritecestla__3856f2    2.946440 -0.022076  \n",
       "laveritecestla__37vkfp    2.958236  0.005544  \n",
       "laveritecestla__39m37w    2.957072       NaN  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_corpus.get_speaker_convo_attribute_table(attrs=['div__self', 'div__other', 'div__adj']).dropna(subset=['div__self', 'div__other', 'div__adj'], how='all').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
